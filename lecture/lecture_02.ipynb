{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2\n",
    "\n",
    "$$\n",
    "\\global\\let\\phi=\\varphi\n",
    "\\global\\let\\eps=\\varepsilon\n",
    "\\gdef\\N{\\mathbb{N}}\n",
    "\\gdef\\F{\\mathbb{F}}\n",
    "\\gdef\\R{\\mathbb{R}}\n",
    "\\gdef\\C{\\mathbb{C}}\n",
    "\\gdef\\L{\\mathcal{L}}\n",
    "\\gdef\\mat{\\mathrm{mat}}\n",
    "\\gdef\\norm#1{\\|#1\\|}\n",
    "\\gdef\\matrix#1{\\begin{pmatrix}#1\\end{pmatrix}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture we recapitulate the definitions and base properties of vector and matrix norms and of the eigenvalue decomposition. Norms will soon let us analyze the convergence of iterative methods for linear systems, which will be quantified in terms of the spectral properties of matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector and Matrix Norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definiton 2.1\n",
    "\n",
    "Let $V$ be a vector space over a field $\\F$. A function $\\norm{\\cdot} : V \\to \\R$ is called a **norm** on $V$ if\n",
    "\n",
    "$$\\begin{alignat*}{2}\n",
    "    \\text{(i)} &\\quad \\text{(non-negativity)} \\quad && \\norm{v} \\ge 0 \\ \\forall v \\in V \\\\\n",
    "    \\text{(ii)} &\\quad \\text{(non-degeneracy)} \\quad && \\norm{v} \\ne 0 \\ \\forall v \\in V \\\\\n",
    "    \\text{(iii)} &\\quad \\text{(homogeneity)} \\quad && \\norm{\\alpha \\ v} = |\\alpha| \\ \\norm{v} \\ \\forall \\alpha \\in \\F \\ \\forall v \\in V \\\\\n",
    "    \\text{(iv)} &\\quad \\text{(triangle inequality)} \\quad && \\norm{u + v} \\le \\norm{u} + \\norm{v} \\ \\forall u,v \\in V\n",
    "\\end{alignat*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2.2\n",
    "\n",
    "Let $V = \\F^n$ for $n \\in \\N$.\n",
    "\n",
    "- $\\displaystyle \\norm{v}_\\infty = \\max_{i \\in \\{1, \\dots, n\\}} |v_i| \\quad \\forall v \\in V$\n",
    "\n",
    "- $\\displaystyle \\norm{v}_p = \\bigg( \\sum_{i=1}^n |v_i|^p \\bigg)^{\\frac{1}{p}}$ for $p \\in [1, \\infty)$\n",
    "\n",
    "These are called $p$**-norms** for $p \\in [1, \\infty]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition 2.3\n",
    "\n",
    "Let $V = \\F^{m \\times n}$ for $m,n \\in \\N$.\n",
    "\n",
    "- $\\displaystyle \\norm{A}_{\\max} = \\max_{\\substack{i \\in \\{1, \\dots, m\\} \\\\ j \\in \\{1, \\dots, n\\}}} |a_{ij}| \\quad \\forall A \\in V$ is called **Chebyshev norm** in some sources\n",
    "\n",
    "- $\\displaystyle \\norm{A}_F = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n |a_{ij}^2|} \\quad \\forall A \\in V$ is called **Frobenius norm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proposition 2.4\n",
    "\n",
    "Let $U$ and $V$ be vector spaces over a field $\\F$ with norms $\\norm{\\cdot}_U$ and $\\norm{\\cdot}_V$. Let $\\L$ denote the space of linear maps defined on $V$ and taking values in $U$ that are continuous with respect to the norms. Then $\\norm{\\cdot} : \\L \\to \\R$ defined by $$ \\norm{\\phi} = \\sup_{\\substack{v \\in V \\\\ \\norm{v}_V = 1}} \\norm{\\phi(v)}_U \\quad \\forall \\phi \\in \\L $$ is a norm on $\\L$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition 2.5\n",
    "\n",
    "The above norm is called the **operator norm** induced by the norms $\\norm{\\cdot}_V$ and $\\norm{\\cdot}_U$ of the domain and codomain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition 2.6\n",
    "\n",
    "Let $V = \\F^n$ and $U = \\F^m$ for some $m, n \\in \\N$. Consider norms $\\norm{\\cdot}_V$ and $\\norm{\\cdot}_U$ on $V$ and $U$. $\\L$ is identified with $W = \\F^{m \\times n}$ using the standard bases for $V$ and $U$. $$ \\phi \\in \\L \\iff \\mat(\\phi) \\in \\F^{m \\times n} $$ where $\\mat(\\phi)$ is the matrix of $\\phi \\in \\L$ w.r.t. the standard bases of $V$ and $U$:\n",
    "\n",
    "Let $\\norm{\\cdot}$ be the operator norm on $\\L$ induced by $\\norm{\\cdot}_V$ and $\\norm{\\cdot}_U$. Then $\\norm{\\cdot} \\circ \\mat^{-1} : \\F^{m \\times n} \\to \\R$ is called the **matrix operator norm** induced by the norms $\\norm{\\cdot}_V$ and $\\norm{\\cdot}_U$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2.7\n",
    "\n",
    "For $p, q \\in [1, \\infty]$, $m, n \\in \\N$ and $W = \\F^{m \\times n}$: $$ \\norm{A}_{p,q} = \\max_{\\substack{v \\in \\F^n \\\\ \\norm{v}_q = 1}} \\norm{Av}_p \\quad \\forall A \\in W $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition 2.8\n",
    "\n",
    "For $p = q \\in [1, \\infty]$ the notation $\\norm{\\cdot}_p$ is used instead of $\\norm{\\cdot}_{p,q}$ and is called the **matrix $p$-norm**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proposition 2.9\n",
    "\n",
    "Let $n \\in \\N$, $p \\in [1, \\infty]$ then the matrix $p$-norm on $\\F^{n \\times 1}$ coincides with the vector $p$-norm on $\\F^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proposition 2.10\n",
    "\n",
    "Let $m, n \\in \\N$. Then $\\forall A \\in \\F^{m \\times n}$\n",
    "\n",
    "- $\\displaystyle \\norm{A}_1 = \\max_{j \\in \\{1 ,\\ \\dots ,\\ n\\}} \\sum_{i=1}^m |a_{ij}|$\n",
    "\n",
    "- $\\displaystyle \\norm{A}_{\\infty} = \\norm{A^{\\top}}_1 = \\max_{i \\in \\{1 ,\\ \\dots ,\\ m\\}} \\sum_{j=1}^n |a_{ij}|$\n",
    "\n",
    "- $\\norm{A}_2$ is the largest singular value of $A$, i.e. $\\norm{A}_2^2$ is the largest eigenvalue of $A^*A$ and of $AA^*$, and $\\displaystyle \\norm{A}_2 = \\max_{\\substack{u \\in \\mathbb{F}^m ,\\ v \\in \\mathbb{F}^n \\\\ \\norm{u}_2 = \\norm{v}_2 = 1}} |u^* A v|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition 2.11\n",
    "\n",
    "Let $k, m, n \\in \\N$, $U = \\F^{k \\times m}$, $V = \\F^{m \\times n}$, $W = \\F^{k \\times n}$ and let $\\norm{\\cdot}_U$, $\\norm{\\cdot}_V$ and $\\norm{\\cdot}_W$ be norms on $U$, $V$, $W$ respectively.\n",
    "\n",
    "These norms are called **consistent** (or **sub-multiplicative**) if $$ \\norm{AB}_W \\le \\norm{A}_U \\ \\norm{B}_V \\quad \\forall A \\in U \\ \\forall B \\in V$$\n",
    "\n",
    "For $U = V = W$ and $\\norm{\\cdot}_U = \\norm{\\cdot}_V = \\norm{\\cdot}_W$ this reduces to $$ \\norm{AB}_W = \\norm{A}_W \\ \\norm{B}_W \\quad \\forall A ,\\, B \\in W $$ which is referred to as the **consistency** (**sub-multiplicity**) of the norm $\\norm{\\cdot}_W$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proposition 2.12\n",
    "\n",
    "Let $n \\in \\N$.\n",
    "\n",
    "- The $p$-norm on $\\F^{n times n}$ is consistent for $p \\in \\{1 ,\\, 2 ,\\, \\infty\\}$.\n",
    "- The Frobenius norm on $\\F^{n \\times n}$ is consistent.\n",
    "- The Chebyshev norm is not generally consistent, e.g. for $A = \\matrix{1 & 1 \\\\ 1 & 1}$ we have $2 = \\norm{AA}_{\\max} \\nleq \\norm{A} \\ \\norm{A} = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proposition 2.13\n",
    "\n",
    "Let $n \\in \\N$ and $\\norm{\\cdot}$ be a norm on $\\F^{n \\times n}$. For invertible $U \\in \\F^{n \\times n}$ consider $\\norm{\\cdot}_*$, $\\norm{\\cdot}_{**}$, $\\norm{\\cdot}_{***} : \\F^{n \\times n} \\to \\R$ given $\\forall A \\in \\F^{n \\times n}$ by\n",
    "\n",
    "- $\\norm{A}_* = \\norm{U A}$\n",
    "- $\\norm{A}_{**} = \\norm{A U}$\n",
    "- $\\norm{A}_{***} = \\norm{U^{-1} A U}$ where $U^{-1} A U$ is called a similarity transform\n",
    "\n",
    "These are norms on $\\F^{n \\times n}$ and they are consistent if $\\norm{\\cdot}$ is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvalues of Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition 2.14\n",
    "\n",
    "Let $n \\in \\N$, $A \\in \\F^{n \\times n}$, $\\lambda \\in \\F$. If $\\ker(A - \\lambda I) \\ne \\{0\\}$ then $\\lambda$ is called a n **eigenvalue** of $A$.\n",
    "\n",
    "Any non-zero element of $\\ker(A - \\lambda I)$ is called an **eigenvector** of $A$ corresponding to eigenvalue $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition 2.15\n",
    "\n",
    "Let $n \\in \\N$, $A \\in \\F^{n \\times n}$. The function $\\chi_A : \\F \\to \\F ,\\ \\chi_A(\\lambda) = \\det(A - \\lambda I)$ is called the **characteristic polynomial** of $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proposition 2.16\n",
    "\n",
    "Let $n \\in \\N$ and $A \\in \\F^{n \\times n}$. Then $\\chi_A$ is a polynomial of degree $n$ with leading coefficient $(-1)^n$. Furthermore any $\\lambda \\in \\F$ is an eigenvalue of $A$ if and only if it is a root of $\\chi_A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition 2.17\n",
    "\n",
    "Let $n \\in \\N$, $A \\in \\F^{n \\times n}$ and $\\lambda \\in \\F$. If $\\lambda$ is a root of $\\chi_A$ of multiplicity $m \\in \\N$ then $\\lambda$ is said to be an eigenvalue of $A$ of **algebraic multiplicity** $m$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition 2.18\n",
    "\n",
    "Let $n \\in \\N$, $A \\in \\F$ and $\\lambda \\in \\F$ be an eigenvalue of $A$. Then $\\lambda$ is said to be an eigenvalue of $A$ of **geometric multiplicity** $\\dim \\ker(A - \\lambda I)$.\n",
    "\n",
    "If the geometric multiplicity of eigenvalue $\\lambda$ is less than its algebraic multiplicity then $\\lambda$ is said to be a **defective eigenvalue**. If the two multiplicities are equal then $\\lambda$ is said to be a **non-defective eigenvalue** of $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schur Canonical Form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition 2.19\n",
    "\n",
    "Let $n \\in \\N$, $A \\in \\C^{n \\times n}$. Assume that $Q \\in \\C^{n \\times n}$is a unitary matrix and that the matrix $T = Q^* A Q$ is upper-triangular. Then $T$ is called a **Schur canonical form** of $A$.\n",
    "\n",
    "The factorization $A = Q T Q^*$ is called a **Schur decomposition** of $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proposition 2.20\n",
    "\n",
    "In the context of definition 2.19 the diagonal entries of $T$ are the eigenvalues of $A$ repeated according to their algebraic multiplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theorem 2.21\n",
    "\n",
    "Let $n \\in \\N$, $A \\in \\F^{n \\times n}$ and $\\lambda_1 ,\\ \\dots ,\\ \\lambda_n \\in \\C$ be the eigenvalues of $A$ according to their algebraic multiplicity.\n",
    "\n",
    "Then there exists a unitary matrix $Q \\in \\C^{n \\times n}$ such that the matrix $T = Q^* A Q$ is upper-triangular with diagonal entries $\\lambda_1,\\ \\dots,\\ \\lambda_n$.\n",
    "\n",
    "##### Proof\n",
    "\n",
    "Let $x_1$ be a unit eigenvalue of $A$ corresponding to the eigenvalue $\\lambda_1$. Consider a matrix $X_1 \\in \\C^{n \\times (n-1)}$ such that $X = \\matrix{x_1 && X_1} \\in \\C^{n \\times n}$ is unitary. Then $$ X^* A X = \\matrix{x_1 \\\\ X_1} \\ A \\ \\matrix{x_1 && X_1} = \\matrix{x_1^* A x_1 && x_1^* A X_1 \\\\ X_1^* A x_1 && X_1^* A X_1} = \\matrix{\\lambda_1 && t_1^* \\\\ 0 && A_1} $$ where $t_1 = X_1^* A^* x_1 \\in \\C^{n-1}$ and $A_1 = X_1^* A X_1 \\in \\C^{(n-1) \\times (n-1)}$. The bottom-left block is zero since $X_1^* A x_1 = X_1^* \\lambda_1 x_1 = \\lambda_1 \\cdot 0 = 0 \\in \\C^{n-1}$ because for $X$ to be unitary $X_1 x_1$ has to be zero.\n",
    "\n",
    "For any $\\lambda \\in \\C$ we have $\\det(A - \\lambda I) = \\det(X^* A X - \\lambda I) = (\\lambda_1 - \\lambda) \\det(A_1 - \\lambda I)$. This means that for any $\\lambda \\in \\C$ and $m \\in \\N$ the statements\n",
    "\n",
    "- $\\lambda$ is a root of $\\chi_A$ if multiplicity $m$\n",
    "- $\\lambda$ is a root of $\\chi_{A_1}$ of multiplicity $\\begin{cases} m, \\quad &\\lambda \\ne \\lambda_1 \\\\ m-1, \\quad &\\lambda = \\lambda_1 \\end{cases}$\n",
    "\n",
    "are equivalent. Then by proposition 2.16 and definition 2.17 $\\lambda_2,\\ \\dots,\\ \\lambda_n$ is the list of eigenvalues of $A$ repeated according to their algebraic multiplicity.\n",
    "\n",
    "On the other hand if $Q_1 \\in \\C^{(n-1) \\times (n-1)}$ is a unitary matrix such that $T_1 = Q_1^* A Q_1$ is upper-triangular with diagonal entries $\\lambda_2 ,\\ \\dots ,\\ \\lambda_n$ then $Q = X \\ \\matrix{1 && \\\\  && Q_1}$ and $T = \\matrix{\\lambda_1 && t_1^* Q_1 \\\\ && T_1}$ fulfull the claim for $A$.\n",
    "\n",
    "Naturally for $n = 1$, $Q = \\matrix{1}$ and $T = A$ fulfill the claim.\n",
    "\n",
    "By induction the claim holds for any $n \\in \\N$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
